[
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "ca147ff1-9d22-4ba5-a811-7b16351ae02d",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC001-verify_health_api_returns_correct_status_version_environment",
    "description": "Test the /api/v1/health/health GET endpoint to ensure it returns the current system status, version, and environment information correctly without errors.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8080\"\nHEALTH_ENDPOINT = \"/api/v1/health/health\"\nTIMEOUT = 30\n\ndef test_verify_health_api_returns_correct_status_version_environment():\n    url = BASE_URL + HEALTH_ENDPOINT\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=TIMEOUT)\n    except requests.RequestException as e:\n        assert False, f\"Request to Health API failed: {e}\"\n    \n    assert response.status_code == 200, f\"Expected status code 200 but got {response.status_code}\"\n    try:\n        json_data = response.json()\n    except ValueError:\n        assert False, \"Response is not a valid JSON\"\n    \n    # Validate required fields presence and type\n    for field in [\"status\", \"version\", \"environment\"]:\n        assert field in json_data, f\"Response JSON missing required field '{field}'\"\n        assert isinstance(json_data[field], str), f\"Field '{field}' is not a string\"\n        assert json_data[field].strip() != \"\", f\"Field '{field}' should not be empty\"\n        \ntest_verify_health_api_returns_correct_status_version_environment()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 29, in <module>\n  File \"<string>\", line 17, in test_verify_health_api_returns_correct_status_version_environment\nAssertionError: Expected status code 200 but got 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.324Z",
    "modified": "2025-10-17T20:38:41.566Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "36120bbf-fc0f-4c34-8aa1-977687c76d80",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC002-verify_pdf_upload_endpoint_handles_file_upload_and_size_limit",
    "description": "Test the /api/v1/pdfs/upload POST endpoint to verify successful PDF file upload, correct storage, registration in the RAG ingestion system, and proper error handling for files exceeding size limits.",
    "code": "import requests\nimport io\nimport os\n\nBASE_URL = \"http://localhost:8080\"\nUPLOAD_ENDPOINT = \"/api/v1/pdfs/upload\"\nLIST_ENDPOINT = \"/api/v1/pdfs/list\"\nDELETE_ENDPOINT = \"/api/v1/pdfs/{filename}\"\nRAG_STATUS_ENDPOINT = \"/api/v1/rag/rag-status\"\n\nTIMEOUT = 30\n\n\ndef test_verify_pdf_upload_endpoint_handles_file_upload_and_size_limit():\n    # Helper to delete pdf by filename\n    def delete_pdf(filename):\n        url = BASE_URL + DELETE_ENDPOINT.format(filename=filename)\n        try:\n            resp = requests.delete(url, timeout=TIMEOUT)\n            resp.raise_for_status()\n        except Exception:\n            pass  # best effort delete to cleanup\n\n    # Prepare a small valid PDF content (simple PDF header and minimal content)\n    small_pdf_content = b'%PDF-1.4\\n1 0 obj\\n<< /Type /Catalog >>\\nendobj\\nxref\\n0 1\\n0000000000 65535 f \\ntrailer\\n<< /Root 1 0 R >>\\nstartxref\\n9\\n%%EOF\\n'\n    small_pdf_filename = \"test_upload_small.pdf\"\n\n    # Prepare a large PDF content to exceed size limits (assume >50MB to trigger 413)\n    # We'll simulate a large file by repeating bytes - exact size depends on server limit,\n    # but let's use 60MB as a common size limit example.\n    large_pdf_content = b'%PDF-1.4\\n' + (b'0' * (60 * 1024 * 1024)) + b'\\n%%EOF\\n'\n    large_pdf_filename = \"test_upload_large.pdf\"\n\n    # 1) Test successful upload of small PDF file\n    files = {\n        \"file\": (small_pdf_filename, io.BytesIO(small_pdf_content), \"application/pdf\")\n    }\n    uploaded_filename = None\n    try:\n        upload_url = BASE_URL + UPLOAD_ENDPOINT\n        response = requests.post(upload_url, files=files, timeout=TIMEOUT)\n        assert response.status_code == 200, f\"Expected 200 OK on small file upload, got {response.status_code}\"\n        json_resp = response.json()\n        # Validate response keys\n        assert \"message\" in json_resp and isinstance(json_resp[\"message\"], str), \"Missing or invalid 'message' in upload response\"\n        assert \"file_path\" in json_resp and isinstance(json_resp[\"file_path\"], str), \"Missing or invalid 'file_path' in upload response\"\n        assert \"pdfs_in_directory\" in json_resp and isinstance(json_resp[\"pdfs_in_directory\"], list), \"Missing or invalid 'pdfs_in_directory' in upload response\"\n        # Determine uploaded file name from file_path\n        uploaded_filepath = json_resp[\"file_path\"]\n        # Extract filename from file_path reliably\n        uploaded_filename = os.path.basename(uploaded_filepath)\n        assert uploaded_filename in json_resp[\"pdfs_in_directory\"], \"Uploaded filename not found in 'pdfs_in_directory'\"\n        # Validate that filename is the expected and matches uploaded small PDF\n        assert uploaded_filename.endswith(\".pdf\"), \"Uploaded filename does not end with .pdf\"\n        # Verify RAG ingestion registration by fetching RAG status and confirming the PDF presence\n        rag_resp = requests.get(BASE_URL + RAG_STATUS_ENDPOINT, timeout=TIMEOUT)\n        assert rag_resp.status_code == 200, f\"RAG status call failed with status {rag_resp.status_code}\"\n        rag_json = rag_resp.json()\n        pdf_names = [pdf[\"filename\"] for pdf in rag_json.get(\"pdfs\", [])]\n        assert uploaded_filename in pdf_names, \"Uploaded PDF not registered in RAG ingestion system\"\n    finally:\n        if uploaded_filename:\n            delete_pdf(uploaded_filename)\n\n    # 2) Test error handling for large PDF file upload (expecting status 413)\n    files = {\n        \"file\": (large_pdf_filename, io.BytesIO(large_pdf_content), \"application/pdf\")\n    }\n    response = requests.post(BASE_URL + UPLOAD_ENDPOINT, files=files, timeout=TIMEOUT)\n    # We accept 413 Payload Too Large per PRD; some servers may respond differently but 413 expected\n    assert response.status_code == 413, f\"Expected 413 Payload Too Large for large file, got {response.status_code}\"\n\n\ntest_verify_pdf_upload_endpoint_handles_file_upload_and_size_limit()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 74, in <module>\n  File \"<string>\", line 52, in test_verify_pdf_upload_endpoint_handles_file_upload_and_size_limit\nAssertionError: Uploaded filename not found in 'pdfs_in_directory'\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.331Z",
    "modified": "2025-10-17T20:39:23.631Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "682b29a3-e9c5-469f-a9d8-f777d8a3d7ee",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC003-verify_pdf_list_endpoint_returns_all_pdfs",
    "description": "Test the /api/v1/pdfs/list GET endpoint to ensure it returns a complete and accurate list of all uploaded PDFs with correct metadata.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8080\"\nTIMEOUT = 30\n\ndef test_verify_pdf_list_endpoint_returns_all_pdfs():\n    list_url = f\"{BASE_URL}/api/v1/pdfs/list\"\n    upload_url = f\"{BASE_URL}/api/v1/pdfs/upload\"\n    delete_url_template = f\"{BASE_URL}/api/v1/pdfs/{{filename}}\"\n\n    # Prepare a small PDF content for upload\n    sample_pdf_content = b\"%PDF-1.4\\n%Test PDF content\\n%%EOF\\n\"\n    sample_pdf_filename = \"test_for_list_endpoint.pdf\"\n\n    headers = {}\n\n    # Upload a PDF to ensure there is at least one PDF in the list\n    files = {\n        'file': (sample_pdf_filename, sample_pdf_content, 'application/pdf')\n    }\n\n    uploaded_filename = None\n    try:\n        upload_resp = requests.post(upload_url, files=files, headers=headers, timeout=TIMEOUT)\n        assert upload_resp.status_code == 200, f\"PDF upload failed with status {upload_resp.status_code}\"\n        upload_json = upload_resp.json()\n        assert \"message\" in upload_json\n        assert \"file_path\" in upload_json\n        assert \"pdfs_in_directory\" in upload_json\n        # Extract the uploaded filename from response - usually from last part of file_path or from pdfs_in_directory\n        # We assume uploaded filename is the sample_pdf_filename as sent\n        uploaded_filename = sample_pdf_filename\n\n        # Now call list endpoint\n        list_resp = requests.get(list_url, headers=headers, timeout=TIMEOUT)\n        assert list_resp.status_code == 200, f\"PDF list endpoint failed with status {list_resp.status_code}\"\n\n        list_json = list_resp.json()\n        assert \"pdfs\" in list_json\n        pdfs = list_json[\"pdfs\"]\n        assert isinstance(pdfs, list)\n\n        # There should be at least one PDF (the one we uploaded)\n        assert any(pdf.get(\"filename\") == uploaded_filename for pdf in pdfs), \"Uploaded PDF not found in list\"\n\n        # Validate the metadata for each pdf item according to schema\n        for pdf in pdfs:\n            assert isinstance(pdf, dict)\n            for field in [\"filename\", \"path\", \"size\", \"last_modified\"]:\n                assert field in pdf, f\"Field '{field}' missing in pdf item\"\n            assert isinstance(pdf[\"filename\"], str)\n            assert isinstance(pdf[\"path\"], str)\n            assert isinstance(pdf[\"size\"], int)\n            # last_modified should be a string in ISO 8601 format; basic check\n            assert isinstance(pdf[\"last_modified\"], str)\n            assert len(pdf[\"last_modified\"]) > 0\n\n    finally:\n        # Clean up: delete the uploaded PDF if it was uploaded\n        if uploaded_filename:\n            delete_url = delete_url_template.format(filename=uploaded_filename)\n            try:\n                del_resp = requests.delete(delete_url, headers=headers, timeout=TIMEOUT)\n                # Accept 200 as success, nothing else to assert here\n            except Exception:\n                pass\n\ntest_verify_pdf_list_endpoint_returns_all_pdfs()\n",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.339Z",
    "modified": "2025-10-17T20:38:52.262Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "ff8f478c-c268-482a-bdf7-26638bbc6db8",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC004-verify_pdf_delete_endpoint_removes_specified_pdf",
    "description": "Test the /api/v1/pdfs/{filename} DELETE endpoint to confirm that the specified PDF file is deleted successfully and the response message is accurate.",
    "code": "import requests\nimport os\n\nBASE_URL = \"http://localhost:8080\"\nUPLOAD_ENDPOINT = f\"{BASE_URL}/api/v1/pdfs/upload\"\nDELETE_ENDPOINT_TEMPLATE = f\"{BASE_URL}/api/v1/pdfs/{{filename}}\"\nLIST_ENDPOINT = f\"{BASE_URL}/api/v1/pdfs/list\"\n\nTEST_PDF_CONTENT = b\"%PDF-1.4\\n%Test PDF\\n1 0 obj\\n<<>>\\nendobj\\ntrailer\\n<<>>\\nstartxref\\n9\\n%%EOF\"\n\ndef verify_pdf_delete_endpoint_removes_specified_pdf():\n    filename = None\n    # Step 1: Upload a PDF file to get a filename to delete\n    try:\n        files = {\"file\": (\"test_delete.pdf\", TEST_PDF_CONTENT, \"application/pdf\")}\n        resp_upload = requests.post(UPLOAD_ENDPOINT, files=files, timeout=30)\n        assert resp_upload.status_code == 200, f\"Upload failed with status {resp_upload.status_code}\"\n        upload_json = resp_upload.json()\n        # Extract filename from file_path properly\n        file_path = upload_json.get(\"file_path\")\n        assert file_path, \"Upload response missing 'file_path'\"\n        # Extract the filename from file_path considering both '/' and '\\' separators\n        filename = file_path.replace('\\\\', '/').split('/')[-1].strip()\n        assert filename, \"Could not determine filename from upload response\"\n\n        # Step 2: Confirm the file is present in the list before deletion\n        resp_list_before = requests.get(LIST_ENDPOINT, timeout=30)\n        assert resp_list_before.status_code == 200\n        list_json_before = resp_list_before.json()\n        pdfs_before = [pdf[\"filename\"].strip() for pdf in list_json_before.get(\"pdfs\", []) if \"filename\" in pdf and isinstance(pdf[\"filename\"], str)]\n        assert filename in pdfs_before, f\"Uploaded PDF '{filename}' not found in list before deletion\"\n\n        # Step 3: Delete the uploaded PDF\n        delete_url = DELETE_ENDPOINT_TEMPLATE.format(filename=filename)\n        resp_delete = requests.delete(delete_url, timeout=30)\n        assert resp_delete.status_code == 200, f\"Delete failed with status {resp_delete.status_code}\"\n        delete_json = resp_delete.json()\n        msg = delete_json.get(\"message\", \"\")\n        assert msg, \"Delete response missing 'message'\"\n        assert \"deleted\" in msg.lower() or \"removed\" in msg.lower(), f\"Unexpected delete message: {msg}\"\n\n        # Step 4: Confirm the file is no longer in the list after deletion\n        resp_list_after = requests.get(LIST_ENDPOINT, timeout=30)\n        assert resp_list_after.status_code == 200\n        list_json_after = resp_list_after.json()\n        pdfs_after = [pdf[\"filename\"].strip() for pdf in list_json_after.get(\"pdfs\", []) if \"filename\" in pdf and isinstance(pdf[\"filename\"], str)]\n        assert filename not in pdfs_after, f\"PDF '{filename}' still present in list after deletion\"\n\n    finally:\n        # Cleanup: Attempt to delete the file in case it still exists to avoid test pollution\n        if filename:\n            try:\n                delete_url = DELETE_ENDPOINT_TEMPLATE.format(filename=filename)\n                requests.delete(delete_url, timeout=30)\n            except Exception:\n                pass\n\nverify_pdf_delete_endpoint_removes_specified_pdf()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 58, in <module>\n  File \"<string>\", line 40, in verify_pdf_delete_endpoint_removes_specified_pdf\nAssertionError: Unexpected delete message: PDF 'test_delete.pdf' eliminado exitosamente. La actualización del índice continuará en segundo plano.\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.344Z",
    "modified": "2025-10-17T20:39:22.036Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "7f56b0e1-045d-443b-bb84-5ad3aaf2dd33",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC005-verify_rag_status_endpoint_returns_correct_vector_store_and_pdf_status",
    "description": "Test the /api/v1/rag/rag-status GET endpoint to verify it returns the current status of the RAG vector store, details of ingested PDFs, and total document count accurately.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8080\"\nTIMEOUT = 30\n\ndef test_verify_rag_status_endpoint_returns_correct_vector_store_and_pdf_status():\n    url = f\"{BASE_URL}/api/v1/rag/rag-status\"\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=TIMEOUT)\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n        data = response.json()\n\n        # Validate required keys\n        assert \"pdfs\" in data, \"'pdfs' key missing in response\"\n        assert \"vector_store\" in data, \"'vector_store' key missing in response\"\n        assert \"total_documents\" in data, \"'total_documents' key missing in response\"\n\n        # Validate the types\n        assert isinstance(data[\"pdfs\"], list), \"'pdfs' should be a list\"\n        assert isinstance(data[\"vector_store\"], dict), \"'vector_store' should be a dict\"\n        assert isinstance(data[\"total_documents\"], int), \"'total_documents' should be an int\"\n\n        # Validate vector_store keys and types\n        vector_store = data[\"vector_store\"]\n        for key, expected_type in [(\"path\", str), (\"exists\", bool), (\"size\", int)]:\n            assert key in vector_store, f\"'{key}' key missing in 'vector_store'\"\n            assert isinstance(vector_store[key], expected_type), f\"'{key}' in 'vector_store' should be {expected_type.__name__}\"\n\n        # Validate each pdf detail in pdfs list\n        for pdf in data[\"pdfs\"]:\n            for field, expected_type in [\n                (\"filename\", str),\n                (\"path\", str),\n                (\"size\", int),\n                (\"last_modified\", str),\n            ]:\n                assert field in pdf, f\"'{field}' missing in pdf item\"\n                # Basic type check\n                assert isinstance(pdf[field], expected_type), f\"'{field}' in pdf should be {expected_type.__name__}\"\n            # Optionally check last_modified format (ISO 8601); skipping parsing here\n\n        # total_documents should be consistent with length of pdfs\n        assert data[\"total_documents\"] == len(data[\"pdfs\"]), (\n            f\"total_documents ({data['total_documents']}) does not match number of pdfs ({len(data['pdfs'])})\"\n        )\n\n    except requests.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\ntest_verify_rag_status_endpoint_returns_correct_vector_store_and_pdf_status()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.355Z",
    "modified": "2025-10-17T20:38:35.031Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "7d88fd83-fb70-4251-b362-3043cc0b392e",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC006-verify_rag_clear_endpoint_clears_vector_store_and_updates_status",
    "description": "Test the /api/v1/rag/clear-rag POST endpoint to ensure it correctly clears the RAG vector store, updates the status of remaining PDFs, and returns the appropriate response with status and message.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8080\"\nTIMEOUT = 30\n\ndef test_verify_rag_clear_endpoint_clears_vector_store_and_updates_status():\n    clear_rag_url = f\"{BASE_URL}/api/v1/rag/clear-rag\"\n    rag_status_url = f\"{BASE_URL}/api/v1/rag/rag-status\"\n\n    try:\n        # Get initial RAG status before clearing\n        status_before_resp = requests.get(rag_status_url, timeout=TIMEOUT)\n        assert status_before_resp.status_code == 200, f\"Failed to get RAG status before clear, status code: {status_before_resp.status_code}\"\n        status_before_json = status_before_resp.json()\n        assert isinstance(status_before_json.get(\"pdfs\"), list), \"Initial 'pdfs' must be a list\"\n        assert \"vector_store\" in status_before_json, \"'vector_store' key missing in status before clear\"\n        assert \"total_documents\" in status_before_json, \"'total_documents' key missing in status before clear\"\n\n        # Call clear-rag POST endpoint\n        clear_resp = requests.post(clear_rag_url, timeout=TIMEOUT)\n        assert clear_resp.status_code == 200, f\"Clear RAG endpoint failed, status code: {clear_resp.status_code}\"\n        clear_json = clear_resp.json()\n\n        # Validate response schema and fields\n        expected_keys = {\"status\", \"message\", \"remaining_pdfs\", \"vector_store_size\"}\n        assert expected_keys.issubset(clear_json.keys()), f\"Response keys missing. Expected at least {expected_keys}, got {clear_json.keys()}\"\n        assert isinstance(clear_json[\"status\"], str) and clear_json[\"status\"], \"'status' must be a non-empty string\"\n        assert isinstance(clear_json[\"message\"], str) and clear_json[\"message\"], \"'message' must be a non-empty string\"\n        assert isinstance(clear_json[\"remaining_pdfs\"], int) and clear_json[\"remaining_pdfs\"] >= 0, \"'remaining_pdfs' must be a non-negative integer\"\n        assert isinstance(clear_json[\"vector_store_size\"], int) and clear_json[\"vector_store_size\"] >= 0, \"'vector_store_size' must be a non-negative integer\"\n\n        # Get RAG status after clearing\n        status_after_resp = requests.get(rag_status_url, timeout=TIMEOUT)\n        assert status_after_resp.status_code == 200, f\"Failed to get RAG status after clear, status code: {status_after_resp.status_code}\"\n        status_after_json = status_after_resp.json()\n\n        # After clearing vector store size must be zero or very small (depending on implementation)\n        vector_store_after = status_after_json.get(\"vector_store\", {})\n        assert isinstance(vector_store_after, dict), \"'vector_store' must be a dict after clearing\"\n        vector_store_size_after = vector_store_after.get(\"size\", None)\n        assert vector_store_size_after is not None, \"'size' missing in vector_store after clear\"\n        # Check vector store size matches clear response or is zero\n        assert vector_store_size_after == clear_json[\"vector_store_size\"], \"Vector store size mismatch between clear response and rag-status after clear\"\n        assert vector_store_size_after >= 0, \"Vector store size must be non-negative after clear\"\n\n        # PDFs count after clearing should equal remaining_pdfs from clear response\n        pdfs_after = status_after_json.get(\"pdfs\", [])\n        assert isinstance(pdfs_after, list), \"'pdfs' must be a list after clear\"\n        assert len(pdfs_after) == clear_json[\"remaining_pdfs\"], \"Remaining PDFs count mismatch between clear response and rag-status after clear\"\n\n    except requests.RequestException as e:\n        assert False, f\"HTTP request failed: {e}\"\n\ntest_verify_rag_clear_endpoint_clears_vector_store_and_updates_status()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.361Z",
    "modified": "2025-10-17T20:38:37.233Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "c96edd28-3c18-4b25-a0a9-e9ea7d8af730",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC007-verify_chat_stream_log_endpoint_streams_responses_and_handles_invalid_input",
    "description": "Test the /api/v1/chat/stream_log POST endpoint to verify it streams chat responses correctly and handles invalid input with appropriate error responses.",
    "code": "import requests\nimport json\n\nBASE_URL = \"http://localhost:8080\"\nHEADERS = {\"Content-Type\": \"application/json\"}\nTIMEOUT = 30\n\n\ndef test_verify_chat_stream_log_endpoint_streams_responses_and_handles_invalid_input():\n    url = f\"{BASE_URL}/api/v1/chat/stream_log\"\n\n    # Valid input test - input with required 'input' field\n    valid_payload = {\n        \"input\": \"Hello, how do you work?\"\n    }\n    try:\n        with requests.post(url, json=valid_payload, headers=HEADERS, timeout=TIMEOUT, stream=True) as response:\n            assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n\n            # The endpoint streams response so we should get content incrementally\n            streamed_data = \"\"\n            for line in response.iter_lines(decode_unicode=True):\n                if line:\n                    try:\n                        if line.startswith(\"data: \"):\n                            data_str = line[6:].strip()\n                            if data_str == \"[DONE]\":\n                                break\n                            data_json = json.loads(data_str)\n                            if \"streamed_output\" in data_json:\n                                streamed_data += data_json[\"streamed_output\"]\n                            # else: skip silently\n                    except json.JSONDecodeError:\n                        pass\n            assert len(streamed_data) > 0, \"Streamed output is empty\"\n    except requests.RequestException as e:\n        assert False, f\"Valid input request failed: {e}\"\n\n    # Invalid input test - missing required 'input' field\n    invalid_payload = {\n        \"conversation_id\": \"abc123\"\n    }\n    try:\n        response = requests.post(url, json=invalid_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert response.status_code == 422, f\"Expected 422 for invalid input, got {response.status_code}\"\n        try:\n            resp_json = response.json()\n            assert \"detail\" in resp_json or len(resp_json) > 0\n        except json.JSONDecodeError:\n            pass\n    except requests.RequestException as e:\n        assert False, f\"Invalid input request failed: {e}\"\n\n\ntest_verify_chat_stream_log_endpoint_streams_responses_and_handles_invalid_input()\n",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.370Z",
    "modified": "2025-10-17T20:38:59.561Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "98b5fb44-5f03-46e2-b398-422f9f0c636b",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC008-verify_chat_clear_endpoint_clears_conversation_history",
    "description": "Test the /api/v1/chat/clear/{conversation_id} POST endpoint to confirm it clears the conversation history for the given conversation ID and returns a success message.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://localhost:8080\"\nTIMEOUT = 30\n\n\ndef test_verify_chat_clear_endpoint_clears_conversation_history():\n    session = requests.Session()\n    conversation_id = str(uuid.uuid4())\n    chat_stream_log_url = f\"{BASE_URL}/api/v1/chat/stream_log\"\n    chat_clear_url_template = f\"{BASE_URL}/api/v1/chat/clear/{{conversation_id}}\"\n\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n\n    # Step 1: Create a conversation by sending a chat message with a new conversation_id\n    chat_request_payload = {\n        \"input\": \"Hello, this is a test message for conversation history clearing.\",\n        \"conversation_id\": conversation_id\n    }\n\n    try:\n        stream_response = session.post(chat_stream_log_url, json=chat_request_payload, headers=headers, timeout=TIMEOUT)\n        assert stream_response.status_code == 200, f\"Expected 200 OK from /chat/stream_log, got {stream_response.status_code}\"\n\n        # Step 2: Call clear endpoint to clear the conversation history\n        clear_url = chat_clear_url_template.format(conversation_id=conversation_id)\n        clear_response = session.post(clear_url, timeout=TIMEOUT)\n\n        assert clear_response.status_code == 200, f\"Expected 200 OK from /chat/clear/{conversation_id}, got {clear_response.status_code}\"\n        clear_json = clear_response.json()\n        assert \"message\" in clear_json, \"Response JSON missing 'message' field\"\n        # Usually we'd check for a success message, assume any message means success\n        assert isinstance(clear_json[\"message\"], str) and len(clear_json[\"message\"]) > 0, \"Clear message empty or invalid\"\n\n        # Optionally verify that conversation history is cleared (if API supports checking)\n        # Here we only verify response per instructions\n\n    finally:\n        # No resource deletion endpoint specified for conversation,\n        # so no cleanup needed beyond this point.\n        session.close()\n\n\ntest_verify_chat_clear_endpoint_clears_conversation_history()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 47, in <module>\n  File \"<string>\", line 32, in test_verify_chat_clear_endpoint_clears_conversation_history\nAssertionError: Expected 200 OK from /chat/clear/e358c4c3-4289-445f-8083-8081ce645392, got 500\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.375Z",
    "modified": "2025-10-17T20:39:16.896Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "d9d5d27b-4fae-4064-9c7b-ef89abf7ee9d",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC009-verify_chat_export_conversations_endpoint_generates_excel_file",
    "description": "Test the /api/v1/chat/export-conversations GET endpoint to ensure it exports conversations to an Excel file correctly and handles cases where no data is available.",
    "code": "import requests\nfrom requests.exceptions import RequestException\n\nBASE_URL = \"http://localhost:8080\"\nEXPORT_ENDPOINT = \"/api/v1/chat/export-conversations\"\n\n\ndef test_verify_chat_export_conversations_endpoint_generates_excel_file():\n    url = BASE_URL + EXPORT_ENDPOINT\n    headers = {\n        \"Accept\": \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet, application/json\"\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n    except RequestException as e:\n        assert False, f\"Request to export conversations failed: {e}\"\n\n    # Check for success case: Excel file returned\n    if response.status_code == 200:\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        # The content type for Excel might be one of the following:\n        # application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n        # application/octet-stream (sometimes used)\n        assert \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" in content_type, (\n            f\"Expected Excel file content type, got {content_type}\"\n        )\n        # Also check content is not empty\n        assert response.content and len(response.content) > 0, \"Excel file content is empty\"\n    elif response.status_code == 404:\n        # No data available case\n        # The response is described as 404 with no data\n        # Possibly JSON error message is returned, try to parse\n        try:\n            data = response.json()\n            # We expect some indication of no data; since no schema given, just ensure JSON parse works\n            assert isinstance(data, dict), \"404 response body is not a JSON object\"\n        except Exception:\n            assert False, \"404 response body is not valid JSON\"\n    else:\n        # Unexpected status code\n        assert False, f\"Unexpected status code: {response.status_code}. Response text: {response.text}\"\n\n\ntest_verify_chat_export_conversations_endpoint_generates_excel_file()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.382Z",
    "modified": "2025-10-17T20:38:53.045Z"
  },
  {
    "projectId": "b2ef99fc-698e-4af5-b24d-920e71999a2f",
    "testId": "f517e7d7-c949-4924-b969-773ae22daa69",
    "userId": "34a834f8-30d1-70d1-cb00-b3bbaab7b7c1",
    "title": "TC010-verify_bot_state_endpoints_get_and_toggle_bot_activity",
    "description": "Test the /api/v1/bot/state GET and /api/v1/bot/toggle POST endpoints to verify the bot's current activity state is retrieved correctly and toggling the bot state updates and reflects accurately in the response.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8080\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\"\n}\n\ndef test_verify_bot_state_endpoints_get_and_toggle_bot_activity():\n    # GET current bot state\n    try:\n        get_response = requests.get(f\"{BASE_URL}/api/v1/bot/state\", headers=HEADERS, timeout=TIMEOUT)\n        get_response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"GET /api/v1/bot/state request failed: {e}\"\n    data_get = get_response.json()\n    assert \"is_active\" in data_get and isinstance(data_get[\"is_active\"], bool), \"Response missing or invalid 'is_active'\"\n    assert \"message\" in data_get and isinstance(data_get[\"message\"], str), \"Response missing or invalid 'message'\"\n\n    original_state = data_get[\"is_active\"]\n\n    # POST toggle bot state\n    try:\n        post_response = requests.post(f\"{BASE_URL}/api/v1/bot/toggle\", headers=HEADERS, timeout=TIMEOUT)\n        post_response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"POST /api/v1/bot/toggle request failed: {e}\"\n    data_post = post_response.json()\n    assert \"is_active\" in data_post and isinstance(data_post[\"is_active\"], bool), \"Toggle response missing or invalid 'is_active'\"\n    assert \"message\" in data_post and isinstance(data_post[\"message\"], str), \"Toggle response missing or invalid 'message'\"\n\n    toggled_state = data_post[\"is_active\"]\n    assert toggled_state != original_state, \"Bot state did not toggle\"\n\n    # GET bot state again to confirm toggle\n    try:\n        get_response_after_toggle = requests.get(f\"{BASE_URL}/api/v1/bot/state\", headers=HEADERS, timeout=TIMEOUT)\n        get_response_after_toggle.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"GET /api/v1/bot/state after toggle request failed: {e}\"\n    data_get_after_toggle = get_response_after_toggle.json()\n    assert \"is_active\" in data_get_after_toggle and isinstance(data_get_after_toggle[\"is_active\"], bool), \"Response missing or invalid 'is_active' after toggle\"\n    assert \"message\" in data_get_after_toggle and isinstance(data_get_after_toggle[\"message\"], str), \"Response missing or invalid 'message' after toggle\"\n\n    assert data_get_after_toggle[\"is_active\"] == toggled_state, \"Bot state after toggle GET does not match toggled state\"\n\n    # Toggle back to original state to maintain system consistency\n    try:\n        revert_toggle_response = requests.post(f\"{BASE_URL}/api/v1/bot/toggle\", headers=HEADERS, timeout=TIMEOUT)\n        revert_toggle_response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"POST /api/v1/bot/toggle revert request failed: {e}\"\n    data_revert = revert_toggle_response.json()\n    assert data_revert[\"is_active\"] == original_state, \"Bot state revert toggle failed\"\n\n\ntest_verify_bot_state_endpoints_get_and_toggle_bot_activity()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-10-17T20:38:01.395Z",
    "modified": "2025-10-17T20:38:55.382Z"
  }
]
